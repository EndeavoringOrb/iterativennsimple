{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peformance comparison of different algorithms\n",
    "\n",
    "In this notebook we analyze the performance of various algorithms, including MLPs, dense dynamical systems, and various sorts of sparse dynamical systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# TODO Add these imports and test MaskeLinear and SparseLinear\n",
    "from iterativennsimple.MaskedLinear import MaskedLinear\n",
    "from iterativennsimple.SparseLinear import SparseLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(size, entries, device=\"cuda\"):\n",
    "    \"\"\"create a variety of sparse matrices \n",
    "\n",
    "    Args:\n",
    "        size (int, optional): Size of the square matrix. Defaults to 1000.\n",
    "        entries (int, optional): Total number of non-zero entries. Note this is an upper bound, but should be close to the actual size. Defaults to 23*1000.\n",
    "        device (str, optional): \"cuda\" or \"cpu\". Defaults to \"cuda\".\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of the sparse matrices\n",
    "    \"\"\" \n",
    "    output = {}\n",
    "    # We first create a COO tensor since that is easier to create\n",
    "    indices = torch.randint(0, size, (entries,2))\n",
    "    vals = torch.randn(entries)\n",
    "    coo = torch.sparse_coo_tensor(indices.t(), vals, (size, size), device=device)\n",
    "    coo = coo.coalesce()\n",
    "\n",
    "    # Then we convert it to CSC, CSR and dense\n",
    "    dense = coo.to_dense()\n",
    "    csc = coo.to_sparse_csc()\n",
    "    csr = coo.to_sparse_csr()\n",
    "    \n",
    "    # We also create the MaskedLinear and SparseLinear objects\n",
    "    class moduleWrapper(object):\n",
    "        def __init__(self, module, device=device):\n",
    "            self.module = module\n",
    "            self.device = device\n",
    "        def __matmul__(self, x):\n",
    "            return self.module(x.T).T\n",
    "        \n",
    "    maskedLinear = moduleWrapper(MaskedLinear.from_coo(coo).to(device), device)\n",
    "    sparseLinear = moduleWrapper(SparseLinear.from_coo(coo).to(device), device)\n",
    "\n",
    "    output[\"dense\"] = dense\n",
    "    output[\"coo\"] = coo\n",
    "    output[\"csc\"] = csc\n",
    "    output[\"csr\"] = csr\n",
    "    output[\"maskedLinear\"] = maskedLinear\n",
    "    output[\"sparseLinear\"] = sparseLinear\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check that all of the matrices are the same operator\n",
    "def matrix_check(size, entries, device):\n",
    "    # Generate the matrices\n",
    "    matrices = generate(size, entries, device=device)\n",
    "    # Size of the RHS\n",
    "    x_cols = 100\n",
    "    x = torch.randn(size, x_cols, device=device)\n",
    "\n",
    "    print('Matrix-matrix multiplication check')\n",
    "    y_true = None\n",
    "    base_name = None\n",
    "\n",
    "    for matrix, matrix_name in zip(matrices.values(), matrices.keys()):\n",
    "        y = matrix @ x\n",
    "        if y_true is None:\n",
    "            y_true = y\n",
    "            base_name = matrix_name\n",
    "        else:\n",
    "            print(f\"{matrix_name} == {base_name}: {torch.allclose(y, y_true)}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix-matrix multiplication check\n",
      "coo == dense: False\n",
      "csc == dense: False\n",
      "csr == dense: False\n",
      "maskedLinear == dense: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1000) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmatrix_check\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 19\u001b[0m, in \u001b[0;36mmatrix_check\u001b[0;34m(size, entries, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m     base_name \u001b[38;5;241m=\u001b[39m matrix_name\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatrix_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m == \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1000) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "matrix_check(1000, 23*1000, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_timing(size, entries, device, syncgpu):\n",
    "    # test if cuda is available\n",
    "    if device == \"cuda\":\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"CUDA is not available, using CPU instead\")\n",
    "            device = \"cpu\"\n",
    "\n",
    "    print(f\"Running on {device}\")\n",
    "    print(f\"Size: {size}\")\n",
    "    print(f\"Entries: {entries}\")\n",
    "    print(f\"Synchronize GPU: {syncgpu}\")\n",
    "    \n",
    "    # Generate the matrices\n",
    "    matrices = generate(size, entries, device=device)\n",
    "\n",
    "    # Size of the RHS\n",
    "    x_cols = 100\n",
    "\n",
    "    # Compute the timings\n",
    "    print('Matrix-matrix multiplication timings:')\n",
    "    for matrix, matrix_name in zip(matrices.values(), matrices.keys()):\n",
    "        # first, do a few runs to warm up the cache\n",
    "        for i in range(2):\n",
    "            x = torch.randn(size, x_cols, device=device)\n",
    "            y = matrix @ x\n",
    "        # now do the timings\n",
    "        matrix_times = []\n",
    "        for i in range(5):\n",
    "            x = torch.randn(size, x_cols, device=device)    \n",
    "            if syncgpu:\n",
    "                torch.cuda.synchronize()\n",
    "            start = time.perf_counter()\n",
    "            y = matrix @ x\n",
    "            if syncgpu:\n",
    "                torch.cuda.synchronize()\n",
    "            matrix_time = time.perf_counter()-start\n",
    "            matrix_times.append(matrix_time)\n",
    "        avg_matrix_time = sum(matrix_times)/len(matrix_times)\n",
    "        min_matrix_time = min(matrix_times)\n",
    "        max_matrix_time = max(matrix_times)\n",
    "\n",
    "        print(f'{matrix_name} is on {matrix.device}')\n",
    "        print(f\"{matrix_name} avg time:\", avg_matrix_time)\n",
    "        print(f\"{matrix_name} min time:\", min_matrix_time)\n",
    "        print(f\"{matrix_name} max time:\", max_matrix_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n",
      "Size: 10000\n",
      "Entries: 230000\n",
      "Synchronize GPU: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix-matrix multiplication timings:\n",
      "dense is on cuda:0\n",
      "dense avg time: 0.0006227235309779644\n",
      "dense min time: 0.0006165849044919014\n",
      "dense max time: 0.0006317049264907837\n",
      "coo is on cuda:0\n",
      "coo avg time: 0.00011655818670988082\n",
      "coo min time: 0.00011586863547563553\n",
      "coo max time: 0.00011704117059707642\n",
      "csc is on cuda:0\n",
      "csc avg time: 0.00027557080611586573\n",
      "csc min time: 0.0002740276977419853\n",
      "csc max time: 0.0002782456576824188\n",
      "csr is on cuda:0\n",
      "csr avg time: 5.301395431160927e-05\n",
      "csr min time: 5.24190254509449e-05\n",
      "csr max time: 5.364092066884041e-05\n",
      "maskedLinear is on cuda\n",
      "maskedLinear avg time: 0.0031874104402959346\n",
      "maskedLinear min time: 0.003185573033988476\n",
      "maskedLinear max time: 0.0031895912252366543\n",
      "sparseLinear is on cuda\n",
      "sparseLinear avg time: 0.0004885297268629075\n",
      "sparseLinear min time: 0.00048765214160084724\n",
      "sparseLinear max time: 0.0004896358586847782\n"
     ]
    }
   ],
   "source": [
    "run_timing(10000, 23*10000, \"cuda\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
